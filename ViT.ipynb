{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import timm\n",
    "from timm.optim import create_optimizer_v2\n",
    "from timm.utils import CheckpointSaver\n",
    "import torch.nn.functional as F\n",
    "\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "num_classes = 36\n",
    "using_dataset = f\"food_ai_iccv\"\n",
    "# with open(f\"./{using_dataset}/meta/train.txt\", 'r') as f_train: \n",
    "#     correct_images_filepaths = [f\"./{using_dataset}/images/{line[:-1]}.jpg\" for line in f_train.readlines()]\n",
    "#     #correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n",
    "#     random.shuffle(correct_images_filepaths)\n",
    "#     train_images_paths = correct_images_filepaths\n",
    "\n",
    "# print(len(train_images_paths))\n",
    "\n",
    "# with open(f\"./{using_dataset}/meta/test.txt\", 'r') as f_test: \n",
    "#     test_images_paths = [f\"./{using_dataset}/images/{line[:-1]}.jpg\" for line in f_test.readlines()]\n",
    "#     #test_images_paths = [i for i in test_images_paths if cv2.imread(i) is not None]\n",
    "#     #random.shuffle(test_images_paths)\n",
    "#     #test_images_paths = test_images_paths[:500]\n",
    "\n",
    "# print(len(test_images_paths))\n",
    "# train_images_paths[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '10': 2,\n",
       " '11': 3,\n",
       " '12': 4,\n",
       " '13': 5,\n",
       " '14': 6,\n",
       " '15': 7,\n",
       " '16': 8,\n",
       " '17': 9,\n",
       " '18': 10,\n",
       " '19': 11,\n",
       " '2': 12,\n",
       " '20': 13,\n",
       " '21': 14,\n",
       " '22': 15,\n",
       " '23': 16,\n",
       " '24': 17,\n",
       " '25': 18,\n",
       " '26': 19,\n",
       " '27': 20,\n",
       " '28': 21,\n",
       " '29': 22,\n",
       " '3': 23,\n",
       " '30': 24,\n",
       " '31': 25,\n",
       " '32': 26,\n",
       " '33': 27,\n",
       " '34': 28,\n",
       " '35': 29,\n",
       " '4': 30,\n",
       " '5': 31,\n",
       " '6': 32,\n",
       " '7': 33,\n",
       " '8': 34,\n",
       " '9': 35}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transform_train = transforms.Compose(\n",
    "            [transforms.Resize([256,256]),\n",
    "             transforms.RandomCrop([224,224]),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225]),\n",
    "             ])\n",
    "data_transform_test = transforms.Compose(\n",
    "            [transforms.Resize([224,224]),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225]),\n",
    "             ])\n",
    "\n",
    "ds_train = datasets.ImageFolder(f\"{using_dataset}/Train\", transform=data_transform_train)\n",
    "ds_test = datasets.ImageFolder(f\"{using_dataset}/Test\", transform=data_transform_test)\n",
    "\n",
    "\n",
    "# label2id = ds_test.class_to_idx\n",
    "# id2label = {identifier: label for label, identifier in label2id.items()}\n",
    "\n",
    "# label2id\n",
    "ds_test.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f309037c4f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dl_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "    return (predictions.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "def get_loss(predictions, labels):\n",
    "    predictions = predictions.reshape(-1, predictions.shape[-1])\n",
    "    #labels = labels.unsqueeze(1).expand(-1, 1).reshape(-1)\n",
    "    return F.cross_entropy(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=768, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('vit_base_patch16_224_in21k', pretrained=True, num_classes=num_classes)\n",
    "opt = create_optimizer_v2(model, learning_rate=1e-5)\n",
    "\n",
    "# PATH = f\"./checkpoints/{using_dataset}/ViT/20211028-093107/model.pt\"\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# last_epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "# acc = checkpoint['acc']\n",
    "\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1    Loss: 5.615    Accuracy: 0.015\n"
     ]
    }
   ],
   "source": [
    "df_val = pd.DataFrame()\n",
    "val_labels = []\n",
    "val_pred = []\n",
    "losses, accs = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in dl_test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        loss = get_loss(pred, labels)\n",
    "        acc = get_accuracy(pred, labels)\n",
    "        accs.append(acc * images.shape[0])            \n",
    "        losses.append(loss * images.shape[0])\n",
    "        val_labels.append(labels)\n",
    "        val_pred.append(pred)\n",
    "\n",
    "df_val[f\"epoch_prova_pred\"] = val_pred\n",
    "df_val[f\"epoch_prova_labels\"] = val_labels\n",
    "df_val.to_csv(f\"epoch_prova_val.csv\")\n",
    "loss = torch.stack(losses).sum() / len(dl_test.dataset)\n",
    "acc = torch.stack(accs).sum() / len(dl_test.dataset)\n",
    "\n",
    "print(f'Epoch: {0+1:>2}    Loss: {loss.item():.3f}    Accuracy: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1    Loss: 1.100    Accuracy: 0.734\n",
      "Epoch:  2    Loss: 0.543    Accuracy: 0.863\n",
      "Epoch:  3    Loss: 0.391    Accuracy: 0.896\n",
      "Epoch:  4    Loss: 0.304    Accuracy: 0.919\n",
      "Epoch:  5    Loss: 0.258    Accuracy: 0.930\n",
      "Epoch:  6    Loss: 0.234    Accuracy: 0.933\n",
      "Epoch:  7    Loss: 0.211    Accuracy: 0.940\n",
      "Epoch:  8    Loss: 0.197    Accuracy: 0.941\n",
      "Epoch:  9    Loss: 0.189    Accuracy: 0.945\n",
      "Epoch: 10    Loss: 0.178    Accuracy: 0.945\n",
      "Epoch: 11    Loss: 0.168    Accuracy: 0.950\n",
      "Epoch: 12    Loss: 0.166    Accuracy: 0.951\n",
      "Epoch: 13    Loss: 0.156    Accuracy: 0.950\n",
      "Epoch: 14    Loss: 0.154    Accuracy: 0.956\n",
      "Epoch: 15    Loss: 0.149    Accuracy: 0.955\n",
      "Epoch: 16    Loss: 0.142    Accuracy: 0.957\n",
      "Epoch: 17    Loss: 0.144    Accuracy: 0.959\n",
      "Epoch: 18    Loss: 0.142    Accuracy: 0.958\n",
      "Epoch: 19    Loss: 0.139    Accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "df_val = pd.DataFrame()\n",
    "df_train = pd.DataFrame()\n",
    "output_dir = f\"./checkpoints/{using_dataset}/ViT/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "os.system(f\"mkdir {output_dir}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses, accs = [], []\n",
    "    model.train()\n",
    "    train_labels = []\n",
    "    train_pred = []\n",
    "    for images, labels in dl_train:\n",
    "        opt.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        loss = get_loss(pred, labels)\n",
    "        train_pred.append(pred)\n",
    "        train_labels.append(labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    df_train[f\"epoch_{epoch}_pred\"] = train_pred\n",
    "    df_train[f\"epoch_{epoch}_labels\"] = train_labels\n",
    "    df_train.to_csv(f\"epoch_{epoch}_train.csv\")\n",
    "        \n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_pred = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl_test:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(images)\n",
    "            loss = get_loss(pred, labels)\n",
    "            acc = get_accuracy(pred, labels)\n",
    "            accs.append(acc * images.shape[0])            \n",
    "            losses.append(loss * images.shape[0])\n",
    "            val_labels.append(labels)\n",
    "            val_pred.append(pred)\n",
    "            \n",
    "    df_val[f\"epoch_{epoch}_pred\"] = val_pred\n",
    "    df_val[f\"epoch_{epoch}_labels\"] = val_labels\n",
    "    df_val.to_csv(f\"epoch_{epoch}_val.csv\")\n",
    "    loss = torch.stack(losses).sum() / len(dl_test.dataset)\n",
    "    acc = torch.stack(accs).sum() / len(dl_test.dataset)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:>2}    Loss: {loss.item():.3f}    Accuracy: {acc:.3f}')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict(),\n",
    "        'loss': loss.item(),\n",
    "        'acc': acc\n",
    "    }, f\"{output_dir}/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
