{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import timm\n",
    "from timm.optim import create_optimizer_v2\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "num_classes = 5\n",
    "using_dataset = f\"food-{num_classes}\"\n",
    "using_transformer = \"ViT\"\n",
    "\n",
    "models_transformers = {\n",
    "    'ViT': 'vit_base_patch16_224_in21k',\n",
    "    'CSWin': 'CSWin_64_12211_tiny_224',\n",
    "    'BEiT': 'beit_base_patch16_224_in22k',\n",
    "    'SWin': 'swin_base_patch4_window7_224_in22k',\n",
    "    'DeiT': 'deit_tiny_distilled_patch16_224',\n",
    "}\n",
    "# with open(f\"./{using_dataset}/meta/train.txt\", 'r') as f_train: \n",
    "#     correct_images_filepaths = [f\"./{using_dataset}/images/{line[:-1]}.jpg\" for line in f_train.readlines()]\n",
    "#     #correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]\n",
    "#     random.shuffle(correct_images_filepaths)\n",
    "#     train_images_paths = correct_images_filepaths\n",
    "\n",
    "# print(len(train_images_paths))\n",
    "\n",
    "# with open(f\"./{using_dataset}/meta/test.txt\", 'r') as f_test: \n",
    "#     test_images_paths = [f\"./{using_dataset}/images/{line[:-1]}.jpg\" for line in f_test.readlines()]\n",
    "#     #test_images_paths = [i for i in test_images_paths if cv2.imread(i) is not None]\n",
    "#     #random.shuffle(test_images_paths)\n",
    "#     #test_images_paths = test_images_paths[:500]\n",
    "\n",
    "# print(len(test_images_paths))\n",
    "# train_images_paths[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform_train = transforms.Compose(\n",
    "            [transforms.Resize([256,256]),\n",
    "             transforms.RandomCrop([224,224]),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225]),\n",
    "             ])\n",
    "data_transform_test = transforms.Compose(\n",
    "            [transforms.Resize([224,224]),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225]),\n",
    "             ])\n",
    "\n",
    "ds_train = datasets.ImageFolder(f\"{using_dataset}/train\", transform=data_transform_train)\n",
    "ds_test = datasets.ImageFolder(f\"{using_dataset}/test\", transform=data_transform_test)\n",
    "\n",
    "\n",
    "# label2id = ds_test.class_to_idx\n",
    "# id2label = {identifier: label for label, identifier in label2id.items()}\n",
    "\n",
    "# label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f831ce92670>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dl_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "    return (predictions.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "def get_loss(predictions, labels):\n",
    "    predictions = predictions.reshape(-1, predictions.shape[-1])\n",
    "    #labels = labels.unsqueeze(1).expand(-1, 1).reshape(-1)\n",
    "    return F.cross_entropy(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(models_transformers[using_transformer], pretrained=True, num_classes=num_classes)\n",
    "opt = create_optimizer_v2(model, lr=1e-5)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# PATH = f\"./checkpoints/{using_dataset}/SWin/20211029-071847/model.pt\"\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# last_epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "# acc = checkpoint['acc']\n",
    "\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0    Loss: 2.904    Accuracy: 0.183\n"
     ]
    }
   ],
   "source": [
    "df_val = pd.DataFrame()\n",
    "val_labels = []\n",
    "val_pred = []\n",
    "losses, accs = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in dl_test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        loss = get_loss(pred, labels)\n",
    "        acc = get_accuracy(pred, labels)\n",
    "        accs.append(acc * images.shape[0])            \n",
    "        losses.append(loss * images.shape[0])\n",
    "        val_labels.append(labels.cpu().detach().numpy())\n",
    "        val_pred.append(pred.cpu().detach().numpy())\n",
    "\n",
    "df_val[f\"{using_transformer}_epoch_0_pred\"] = val_pred\n",
    "df_val[f\"{using_transformer}_epoch_0_labels\"] = val_labels\n",
    "df_val.to_csv(f\"results/{using_transformer}_epoch_0_val.csv\")\n",
    "loss = torch.stack(losses).sum() / len(dl_test.dataset)\n",
    "acc = torch.stack(accs).sum() / len(dl_test.dataset)\n",
    "\n",
    "print(f'Epoch: 0    Loss: {loss.item():.3f}    Accuracy: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1    Loss: 0.389    Accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "df_val = pd.DataFrame()\n",
    "df_train = pd.DataFrame()\n",
    "output_dir = f\"./checkpoints/{using_dataset}/{using_transformer}/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "os.system(f\"mkdir {output_dir}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    losses_test, accs_test = [], []\n",
    "    model.train()\n",
    "    train_labels = []\n",
    "    train_pred = []\n",
    "    for images, labels in dl_train:\n",
    "        opt.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(images)\n",
    "        if using_transformer == 'DeiT':\n",
    "            pred = pred[0]\n",
    "        loss = get_loss(pred, labels)\n",
    "        acc = get_accuracy(pred, labels)\n",
    "        train_pred.append(pred.cpu().detach().numpy())\n",
    "        train_labels.append(labels.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    df_train[f\"epoch_{epoch+1}_pred\"] = train_pred\n",
    "    df_train[f\"epoch_{epoch+1}_labels\"] = train_labels\n",
    "    df_train.to_csv(f\"results/{using_transformer}_epoch_{epoch+1}_train.csv\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_pred = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl_test:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(images)\n",
    "            loss = get_loss(pred, labels)\n",
    "            acc = get_accuracy(pred, labels)\n",
    "            accs_test.append(acc * images.shape[0])            \n",
    "            losses_test.append(loss * images.shape[0])\n",
    "            val_labels.append(labels.cpu().detach().numpy())\n",
    "            val_pred.append(pred.cpu().detach().numpy())\n",
    "            \n",
    "    df_val[f\"{using_transformer}_epoch_{epoch}_pred\"] = val_pred\n",
    "    df_val[f\"{using_transformer}_epoch_{epoch}_labels\"] = val_labels\n",
    "    df_val.to_csv(f\"results/{using_transformer}_epoch_{epoch}_val.csv\")\n",
    "    loss = torch.stack(losses_test).sum() / len(dl_test.dataset)\n",
    "    acc = torch.stack(accs_test).sum() / len(dl_test.dataset)\n",
    "    \n",
    "    try:\n",
    "        os.system(f\"rm results/{using_transformer}_epoch_{epoch-2}_train.csv\")\n",
    "        os.system(f\"rm results/{using_transformer}_epoch_{epoch-2}_val.csv\")\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:>2}    Loss: {loss.item():.3f}    Accuracy: {acc:.3f}')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict(),\n",
    "        'loss': loss.item(),\n",
    "        'acc': acc\n",
    "    }, f\"{output_dir}/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
